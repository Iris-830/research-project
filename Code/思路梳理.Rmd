---
title: "思路梳理"
author: "Miao"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

论文题目：Creating data dashboards for visualizing the social
determinants of fistula in women of reproductive age in West Africa
研究问题： a) Analyzing the Social Determinants of Fistula ·Analyze
Socioeconomic, Cultural, Health Service Utilization and Social
Environment Factors:Investigate how various factors such as wealth,
education, occupation, religion, marital status, and access to health
services influence the incidence rates of fistula in different West
African countries. ·Identify Commonalities and Differences:Determine the
commonalities and differences in the influencing factors across the
region to understand the regional variations and specific local dynamics
affecting fistula incidence. b) Predict Trends in Fistula Incidence
Rates ·Predicting Future Incidence:Utilize predictive modeling
techniques to forecast future trends in fistula incidence rates in West
Africa, based on the identified social determinants and current data.
·Propose Targeted Public Health Interventions:Based on the predictions,
propose effective and targeted public health interventions aimed at
reducing the incidence of fistula. These interventions will be tailored
to address the specific needs and conditions of different countries
within the region, thereby improving women's reproductive health
outcomes.

研究方法： 1.描述性统计分析

西非地区，一共选择了6个国家

已计算：

```         
1.描述性统计分析
  Mean(均值),SE(标准误),Median(中位数),Q1(第一四分位数),Q3(第三四分位数),SD(标准差),Min(最小值),Max(最大值)：西非整体变量、各个国家变量
  实际患病率：西非整体、各个国家、各个变量分类下的患病率（西非整体）、各个变量分类下的患病率（各个国家）                   
  实际患病率制图：分组条形图、热力图（各个变量分类下的患病率）
  4组特征分析：西非整体、各个国家
  MCA多重对应分析：西非整体、各个国家 看是否使用plotly图表（交互式）
  
2.西非整体和各国家的13个变量的双变量分析+glm多变量逻辑回归
3.西非整体和各国家的13个变量的决策树
3.西非整体和各国家随机森林模型重要性分数
```

相关性分析（x）： 皮尔逊相关系数、斯皮尔曼相关系数 （用于连续变量）

类别变量分析（x）： 卡方检验（Chi-square test）、方差分析（ANOVA）
（卡方检验用于分类变量
但是只能是二分类；方差分析要求因变量满足正态性假设）

多重对应分析（MCA）

回归分析： 逻辑回归（logistic regression）

可视化工具： 热图（heatmap）、条形图（bar chart）、箱线图（box
plot）、散点图（scatter plot）

特征分析：

1.  个人与家庭背景：当前年龄 宗教信仰 居住地

2.  经济与社会地位：财富指数 教育水平 体力劳动（职业）

3.  医疗服务与健康：产后护理 分娩地点 到医院的距离 生产是否专业

4.  家庭规划与性健康：避孕使用 首次性行为的年龄 总生育数

在描述性统计分析中，除了已经计算的实际患病率和分组条形图、热力图之外，还可以进一步计算和分析以下内容：

### 进一步计算的内容

1.  **人口特征分析**：
    -   按性别、年龄组、婚姻状态、教育水平、收入水平等进行人口特征分析。
    -   计算这些人口特征在西非整体、各个国家、各个变量分类下的分布。
2.  **健康服务利用情况**：
    -   分析产妇在怀孕期间的健康服务利用情况，如产前检查次数、分娩地点、助产士是否专业等。
    -   按西非整体和各个国家计算这些变量的利用率。
3.  **社会文化因素分析**：
    -   分析宗教信仰、婚姻习俗、避孕使用情况等社会文化因素对患病率的影响。
    -   计算这些社会文化因素在西非整体和各个国家下的分布和患病率。
4.  **健康风险因素分析**：
    -   计算和分析与产瘘相关的健康风险因素，如家庭出生数量、出生间隔、是否经历性暴力等。
    -   计算这些健康风险因素在西非整体和各个国家下的分布和患病率。

### 结果展示

通过上述分析，可以展示以下内容：

1.  **人口特征的详细分布**：
    -   按性别和年龄组详细展示人口分布。
    -   各个国家的性别和年龄组分布。
2.  **健康服务利用情况的详细分布**：
    -   按产前检查次数和分娩地点展示健康服务利用情况。
    -   各个国家的健康服务利用情况分布。
3.  **社会文化因素的详细分布**：
    -   按宗教信仰展示社会文化因素分布。
    -   各个国家的社会文化因素分布。

### 总结

通过进一步计算和分析上述内容，可以更全面地了解影响产瘘患病率的各种因素，并为制定公共卫生干预措施提供数据支持。这些分析应涵盖西非整体、各个国家以及各个变量分类下的情况，从而确保结果具有全面性和代表性。

### Dashboard 部分说明

1.  **Dashboard Introduction**：

    -   **介绍背景**：在介绍部分，可以简单说明你将展示的内容和数据背景，解释选择的变量及其理论背景，包括那些在最终模型中未被选中的变量（如
        `age` 和 `residence`）。

2.  **General Overview**：

    -   **展示总体概况**：在这一部分，展示整体数据概况、数据来源和基本统计信息。可以包括
        `age` 和 `residence`
        的分布情况，展示它们在总体数据中的特征和统计描述。

    -   **解释意义**：解释这些变量在总览中的重要性，例如，它们可能与
        `experienced_fistula`
        的关系在其他文献中有所讨论，即使在你的最终模型中没有显著性。

3.  **Variable Overview**：

    -   **详细分析各变量**：在这一部分，你可以对所有相关变量进行详细描述和统计分析，包括
        `age` 和
        `residence`。展示这些变量的分布、类别比例等，并提供初步的单变量分析结果。

    -   **解释这些变量**：说明这些变量为什么在初步分析中被考虑，即使在最终模型中被移除，它们仍可能对理解数据有帮助。

4.  **Multivariate Analysis**：

    -   **展示最终模型**：展示多变量逻辑回归模型的结果，包括哪些变量被纳入最终模型及其显著性。

    -   **解释移除的变量**：解释为什么 `age` 和 `residence`
        在最终模型中被移除。可以提到在多变量分析中，控制其他因素后，这些变量的效果变得不显著。强调这不代表这些变量不重要，只是在当前数据中它们的影响没有达到显著性水平。

5.  **Prediction**：

    -   **场景预测**：展示如何通过不同变量的变化来预测
        `experienced_fistula` 的变化。尽管 `age` 和 `residence`
        在最终模型中被移除，你仍可以通过场景预测展示这些变量的变化如何可能影响结果。

    -   **建议**：提供减少 `experienced_fistula` 的建议时，仍可以提及
        `age` 和
        `residence`，说明它们在理论上可能影响预期结果，并给出相应的干预建议。

### 示例解释

在 dashboard 的 **General Overview** 和 **Variable Overview**
部分，你可以解释：

-   **`Age`**: 虽然在多变量逻辑回归模型中 `age`
    没有显著性，但在数据总体中，`age`
    仍然是一个重要的人口统计学特征。它可能在其他分析中或在与其他变量交互时具有影响。

-   **`Residence`**: `residence`
    的影响可能在多变量模型中被其他变量所遮蔽，或者由于数据集的特定性质，它在单变量分析中并不显著。但这并不意味着它在其他情境或不同的数据集下不重要。

### 1. 预测模型的一致性

确保预测模型与多变量分析结果保持一致非常重要。可以考虑以下策略：

-   **保持一致**：如果你在多变量分析中移除了 `age` 和
    `residence`，建议在预测模型中也不要包含这些变量。这样可以避免模型结果的不一致，保持分析的连贯性。

-   **解释变量的选择**：在预测部分，你可以说明为什么选择或不选择某些变量。你可以解释，尽管
    `age` 和 `residence`
    在当前数据中的多变量分析中不显著，但这些变量在理论上仍然有可能影响结果。因此，在模型的解释部分，你可以提到这些变量可能在不同的数据集或不同的情况下仍然重要。

### 2. 限制性（Limitations）部分

将 `age` 和 `residence`
的不显著性和文献中的相关性放在\*\*限制性（Limitations）\*\*部分是一个很好的方法：

-   **解释背景**：解释文献中的发现与当前数据分析结果之间的差异。这表明你的分析是基于当前数据集的特定情况，而不是完全否定文献中的发现。

-   **可能的原因**：讨论可能的原因为什么这些变量在你的数据中未显著。例如，数据集的样本量、变量的测量方式、潜在的混杂因素等。

-   **对未来研究的建议**：建议未来的研究可以进一步探讨这些变量，并考虑使用不同的数据集或方法进行验证。

\# 打印最佳模型参数

print(rf_model1\$bestTune)

```{r}
# --------------------------------------------------------
# glm 去掉
library(caret)

# 新建一个数据集，去掉 country 列
data_model <- data1 %>% select(-country)

# 确保 experienced_fistula 是因子变量
data_model$experienced_fistula <- as.factor(data_model$experienced_fistula)

# 检查转换是否成功
str(data_model$experienced_fistula)

# 使用 caret 包中的 downSample 函数进行下采样
set.seed(123)  # 设置随机种子以保证结果可重复
data_downsampled <-
  downSample(
    x = data_model %>% select(-experienced_fistula),
    y = data_model$experienced_fistula,
    yname = "experienced_fistula"
  )

# 标准化权重
data_downsampled$V005 <- data_downsampled$V005 / 1000000  # 确保权重处理正确


# 确保权重列在合适的范围内（例如，缩放到 [0, 1] 范围内）
#data_downsampled$V005 <- (data_downsampled$V005 - min(data_downsampled$V005)) / (max(data_downsampled$V005) - min(data_downsampled$V005))


# 下采样后的目标变量从1和2改为0和1
data_downsampled$experienced_fistula <- as.numeric(data_downsampled$experienced_fistula) - 1

# 确保除V005列都是因子类型
data_downsampled <- data_downsampled %>%
  mutate(across(-V005, as.factor))

# 确保 V005 是数值变量
data_downsampled$V005 <- as.numeric(data_downsampled$V005)


# 分割数据集为训练集和测试集
set.seed(123)
train_index <- createDataPartition(data_downsampled$experienced_fistula, p = 0.8, list = FALSE)
train_data <- data_downsampled[train_index, ]
test_data <- data_downsampled[-train_index, ]

# 设置训练控制，包含权重
train_control <- trainControl(method = "cv", number = 10)

# 训练带权重的GLM模型（去掉 V005 列）
set.seed(123)
glm_model <- train(
  experienced_fistula ~ . - V005,
  data = train_data,
  method = "glm",
  family = binomial,
  trControl = train_control,
  weights = train_data$V005,
  metric = "Accuracy"
)

# 查看模型结果
print(summary(glm_model))

# 生成预测
predictions <- predict(glm_model, newdata = test_data)

# 确保预测结果和实际标签都是因子类型，并且具有相同的级别
predictions <- factor(predictions, levels = levels(test_data$experienced_fistula))

# 计算混淆矩阵
confusion_matrix <- confusionMatrix(predictions, test_data$experienced_fistula)
print(confusion_matrix)



library(MASS)
# 提取训练数据
train_data <- data_downsampled[train_index, ]
test_data <- data_downsampled[-train_index, ]

# 提取特征和目标变量
x_train <- train_data %>% dplyr::select(-experienced_fistula, -V005)
y_train <- train_data$experienced_fistula

# 训练初始 GLM 模型（带权重）
initial_model <- glm(experienced_fistula ~ . - V005, data = train_data, family = binomial(), weights = train_data$V005)
summary(initial_model)

# 进行逐步回归
optimized_model <- stepAIC(initial_model, direction = "both", criterion = "BIC")
summary(optimized_model)




# 提取优化后的模型公式
optimized_formula <- formula(optimized_model)
print(optimized_formula)



# 训练优化后的 GLM 模型
optimized_glm_model <- glm(
  optimized_formula,
  data = train_data,
  family = binomial(),
  weights = train_data$V005
)

# 查看优化后的模型结果
summary(optimized_glm_model)

# 生成预测
predictions <- predict(optimized_glm_model, newdata = test_data, type = "response")

# 将预测概率转换为类别标签
predicted_classes <- ifelse(predictions > 0.5, 1, 0)

# 确保预测结果和实际标签都是因子类型，并且具有相同的级别
predicted_classes <- factor(predicted_classes, levels = levels(test_data$experienced_fistula))

# 计算混淆矩阵
library(caret)
confusion_matrix <- confusionMatrix(predicted_classes, test_data$experienced_fistula)
print(confusion_matrix)

```

```{r}
# random forest
# 尝试其他分类模型，例如随机森林
# 新建一个数据集，去掉 country 列
data_model <- data1 %>% select(-country -age -residence)

# 确保 experienced_fistula 是因子变量
data_model$experienced_fistula <- as.factor(data_model$experienced_fistula)

# 检查转换是否成功
str(data_model$experienced_fistula)
library(caret)
# 使用 caret 包中的 downSample 函数进行下采样
set.seed(123)  # 设置随机种子以保证结果可重复
data_downsampled <-
  downSample(
    x = data_model %>% select(-experienced_fistula),
    y = data_model$experienced_fistula,
    yname = "experienced_fistula"
  )

# 标准化权重
data_downsampled$V005 <- data_downsampled$V005 / 1000000  # 确保权重处理正确


# 确保权重列在合适的范围内（例如，缩放到 [0, 1] 范围内）
#data_downsampled$V005 <- (data_downsampled$V005 - min(data_downsampled$V005)) / (max(data_downsampled$V005) - min(data_downsampled$V005))


# 下采样后的目标变量从1和2改为0和1
data_downsampled$experienced_fistula <- as.numeric(data_downsampled$experienced_fistula) - 1

# 确保除V005列都是因子类型
data_downsampled <- data_downsampled %>%
  mutate(across(-V005, as.factor))

# 确保 V005 是数值变量
data_downsampled$V005 <- as.numeric(data_downsampled$V005)


# 分割数据集为训练集和测试集
set.seed(123)
train_index <- createDataPartition(data_downsampled$experienced_fistula, p = 0.8, list = FALSE)
train_data <- data_downsampled[train_index, ]
test_data <- data_downsampled[-train_index, ]

# 设置训练控制，包含权重
train_control <- trainControl(method = "cv", number = 10)

set.seed(123)
tune_grid <- expand.grid(mtry = c(3, 5, 7, 9))
rf_model <- train(
  experienced_fistula ~ . - V005,
  data = train_data,
  method = "rf",
  trControl = train_control,
  weights = train_data$V005,
  metric = "Accuracy",
  ntree = 100,
  tuneGrid = tune_grid
)

# 查看随机森林模型结果
print(summary(rf_model))

# 生成随机森林模型预测
rf_predictions <- predict(rf_model, newdata = test_data)
rf_predictions <- factor(rf_predictions, levels = levels(test_data$experienced_fistula))

# 计算随机森林模型混淆矩阵
rf_confusion_matrix <- confusionMatrix(rf_predictions, test_data$experienced_fistula)
print(rf_confusion_matrix)

# 提取特征重要性
importance_scores <- importance(rf_model$finalModel)
print(importance_scores)
```

特征重要性评分后，去掉age、age_sex

```{r}
# 去特征
set.seed(123)
tune_grid <- expand.grid(mtry = c(2, 4, 6))
rf_model <- train(
  experienced_fistula ~ . - V005 - age_sex,
  data = train_data,
  method = "rf",
  trControl = train_control,
  weights = train_data$V005,
  metric = "Accuracy",
  ntree = 100,
  tuneGrid = tune_grid
)

# 查看随机森林模型结果
print(summary(rf_model))

# 生成随机森林模型预测
rf_predictions <- predict(rf_model, newdata = test_data)
rf_predictions <- factor(rf_predictions, levels = levels(test_data$experienced_fistula))

# 计算随机森林模型混淆矩阵
rf_confusion_matrix <- confusionMatrix(rf_predictions, test_data$experienced_fistula)
print(rf_confusion_matrix)
```

在决定是否将变量纳入模型时，尤其是在处理不平衡数据和多国家数据时，需要权衡多种因素。你的目标是确保模型的性能最佳，并考虑到变量的选择可能会影响最终模型的表现。以下是一些关于如何处理变量选择的建议和方法：

### 1. **双变量分析的使用**

-   **显著性标准**：
    -   如果你决定仅将在双变量分析中显著的变量纳入模型，那么你可能会遇到变量数量不足的问题。这是因为在实际数据中，许多变量可能不会在单独的双变量分析中表现出显著性，但它们可能在多变量模型中发挥作用。
-   **变量选择**：
    -   将显著性作为一个参考点是合理的，但这也意味着你可能遗漏了一些在多变量环境中有影响的变量。显著性仅反映了每个变量与目标变量之间的关系，而不考虑其他变量的共同作用。

### 2. **保持变量一致性**

-   **模型一致性**：
    -   如果变量在西非整体模型中表现出较好的预测能力，可能值得保留这些变量，即使它们在特定国家的双变量分析中未显著。整体模型可能通过捕捉数据的全局模式来提高准确性。
-   **跨国家一致性**：
    -   维持变量的一致性有助于模型在不同国家之间的比较和解释。如果你只依赖于单国家的双变量分析，可能会丧失这种一致性。

### 3. **多变量分析的优势**

-   **考虑交互作用**：
    -   在多变量模型中，变量的交互作用和组合效应可能会显著影响模型的表现。某些变量在单独分析时可能不会显示显著，但在组合分析时可能会变得重要。
-   **模型复杂性**：
    -   复杂的模型可能更能捕捉数据中的复杂模式，即使某些变量在单独的双变量分析中未显著。

### 4. **建议的方法**

1.  **保留变量一致性**：

    -   在模型中保留与西非整体一致的变量，尤其是在变量选择可能影响模型表现的情况下。你可以在模型训练后评估这些变量的实际贡献。

2.  **变量重要性评估**：

    -   在训练随机森林模型后，使用变量重要性度量来评估每个变量的贡献。即使某些变量在单独的分析中不显著，它们可能在多变量模型中仍然很重要。

    ``` r
    # 训练随机森林模型
    rf_model <- randomForest(experienced_fistula ~ ., data = data_model1)

    # 评估变量重要性
    importance(rf_model)
    ```

3.  **交叉验证**：

    -   通过交叉验证来评估模型性能，确保模型的稳定性和泛化能力。

    ``` r
    library(caret)
    cv_results <- train(experienced_fistula ~ ., data = data_model1, method = "rf", trControl = trainControl(method = "cv", number = 10))
    print(cv_results)
    ```

4.  **多模型比较**：

    -   试验不同的模型和特征集，以找到最佳的变量组合。比较使用不同变量集的模型表现，选择表现最好的模型。

### 总结

-   **保持变量一致性**：在模型中保留与西非整体一致的变量可以保持模型的一致性和稳定性，尤其是在多国家数据分析中。
-   **评估变量贡献**：使用模型训练后的变量重要性度量来评估各个变量的实际贡献。
-   **多方法验证**：结合交叉验证和多模型比较，以确保模型的性能和泛化能力。

通过这些方法，你可以更全面地评估和优化模型的表现，确保在处理不平衡数据和多国家数据时获得最佳结果。

,-distance,-age_sex,-number_birth,-education,-wealth,-contraception_use,-delivery_place,-delivery_professional,-postpartum_care

Given the issues you've described with sample sizes when splitting by
country, focusing on predicting fistula prevalence for West Africa as a
whole is a valid approach. Here’s how you can justify this decision and
integrate it into your dashboard and thesis:

### Justification:

1.  **Sample Size Considerations:**
    -   For some countries, the sample size is too small to provide
        reliable predictions. By pooling data from all countries, you
        increase the overall sample size, improving model stability and
        accuracy.
2.  **Generalization:**
    -   While country-specific models are ideal, a region-wide model can
        still provide valuable insights. It can identify broad trends
        and risk factors that are applicable across the region.
3.  **Consistency:**
    -   A single model for West Africa ensures consistency in
        predictions and avoids the pitfalls of having highly variable
        performance across different countries due to sample size
        issues.

### Dashboard Explanation:

-   **Overview Section:**
    -   Present overall findings for West Africa, highlighting the key
        predictors identified by the model.
    -   Explain that due to sample size constraints, a regional model
        was used to ensure robustness and reliability of predictions.
-   **Country Insights:**
    -   Provide comparative statistics and visualizations for each
        country, but clearly indicate that the predictive model applies
        to the region as a whole.
    -   Use descriptive analytics (e.g., prevalence rates,
        socio-economic indicators) to provide context for each country
        without relying on predictive models.

### Thesis Explanation:

-   **Methodology Section:**
    -   Detail the initial approach of building country-specific models
        and the challenges faced due to small sample sizes.
    -   Justify the decision to use a regional model based on
        statistical reliability and the need for consistent, actionable
        insights.
-   **Results Section:**
    -   Present the findings of the regional model, including key
        predictors and their implications.
    -   Discuss any observed variations between countries based on
        descriptive statistics and how these variations were considered
        in the regional model.
-   **Discussion Section:**
    -   Reflect on the limitations of not having country-specific
        predictive models.
    -   Highlight the strengths of the regional approach and suggest
        that future studies with larger datasets might revisit
        country-specific modeling.
    -   Emphasize the importance of region-wide interventions while
        acknowledging the unique needs of each country.

### Implementation Steps:

1.  **Model Training:**
    -   Train a random forest model on the combined dataset for West
        Africa.
    -   Ensure proper handling of class imbalance using techniques like
        SMOTE.
2.  **Model Evaluation:**
    -   Validate the model using cross-validation and report metrics
        like accuracy, precision, recall, F1 score, and ROC-AUC.
3.  **Dashboard Development:**
    -   Create visualizations for the model’s predictions at the
        regional level.
    -   Include country-specific descriptive insights to provide a
        comprehensive view.

### Example Code Snippet:

Here’s a snippet to train and evaluate the model on the combined
dataset:

``` r
library(caret)
library(dplyr)
library(ROCR)

# Combine data
data_combined <- data1 %>%
  select(-country) %>%
  mutate(experienced_fistula = as.factor(experienced_fistula))

# Handle imbalance
set.seed(123)
data_combined_balanced <- SMOTE(experienced_fistula ~ ., data = data_combined, perc.over = 100, perc.under = 200)

# Split data
set.seed(123)
train_index <- createDataPartition(data_combined_balanced$experienced_fistula, p = 0.8, list = FALSE)
train_data <- data_combined_balanced[train_index, ]
test_data <- data_combined_balanced[-train_index, ]

# Train model
train_control <- trainControl(method = "cv", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)
set.seed(123)
rf_model <- train(
  experienced_fistula ~ .,
  data = train_data,
  method = "rf",
  trControl = train_control,
  metric = "ROC"
)

# Evaluate model
rf_predictions <- predict(rf_model, newdata = test_data)
rf_prob <- predict(rf_model, newdata = test_data, type = "prob")[,2]
confusionMatrix(rf_predictions, test_data$experienced_fistula)
roc_curve <- roc(test_data$experienced_fistula, rf_prob)
plot(roc_curve)
```

By following this approach, you can confidently present a robust
analysis in your thesis and on your dashboard.

是的，您可以选择在GLM部分不加交互项，并专注于主要变量的分析。这样做可以保持模型的简单性和解释性。同时，您可以在随机森林模型中进行预测分析，因为随机森林可以自动捕捉变量之间的交互作用。

### 具体步骤：

1.  **GLM部分**：
    -   保持模型的简单性，只包括主要变量而不加交互项。
    -   这部分的目的是展示变量的单独效应，便于解释和理解。
2.  **随机森林模型**：
    -   用于预测分析，因为随机森林在处理高维和复杂数据集时表现优异，并且能够捕捉到变量之间的复杂交互作用。
3.  **在建议部分使用这四方面**：
    -   您可以在给出建议时，结合个人与家庭背景、经济与社会地位、医疗服务与健康、家庭规划与性健康这四方面的结果，提出有针对性的干预措施。

### 示例：

在描述性统计和多变量逻辑回归分析部分，您可以展示各个主要变量对瘘管发生的影响，如：

-   年龄
-   距离
-   宗教信仰
-   教育水平
-   产后护理

在预测分析部分，您可以使用随机森林模型进行分析，并在Dashboard中展示预测结果和模型性能。

### 结论：

通过这种方法，您可以在论文和Dashboard中既展示主要变量的独立效应，又利用随机森林模型的强大预测能力，提供准确的预测和全面的分析。这样可以为决策者提供更有针对性的建议，提高妇女的生殖健康结果。

尽管模型的绝对准确率只有65%，它仍然可以通过以下方式为公共卫生政策制定者提供有价值的决策支持：

1.  **特征重要性分析**：识别关键影响因素，制定有针对性的干预策略。

2.  **相对变化和趋势分析**：模拟不同情景下患病率的相对变化，帮助理解关键因素的变化对患病率的影响。

3.  **数据驱动的决策支持**：通过交互式仪表盘和数据可视化工具，使复杂的数据分析结果更加直观和易于理解，从而支持更好的决策。

这些方法和工具将帮助公共卫生政策制定者更好地利用数据，做出更明智的决策，从而改善西非妇女的健康状况。希望这些建议对你的研究有所帮助。

```{r}
# glm预测部分

####
library(ggplot2)

# 绘制预测概率分布图
ggplot(data1, aes(x = predicted_prob)) +
  geom_histogram(binwidth = 0.01, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Predicted Probability Distribution of Fistula",
       x = "Predicted Probability",
       y = "Frequency") +
  theme_minimal()

# 绘制预测概率随年龄变化的散点图
ggplot(data1, aes(x = as.numeric(age), y = predicted_prob, color = as.factor(distance))) +
  geom_point() +
  facet_wrap(~ education) +
  labs(title = "GLM Predictions for Fistula by Age and Education",
       x = "Age",
       y = "Predicted Probability") +
  theme_minimal()

# 绘制预测概率与财富的关系
ggplot(data1, aes(x = wealth, y = predicted_prob)) +
  geom_boxplot() +
  labs(title = "Predicted Probability of Fistula by Wealth",
       x = "Wealth",
       y = "Predicted Probability") +
  theme_minimal()

# 绘制预测概率与宗教的关系
ggplot(data1, aes(x = religion, y = predicted_prob)) +
  geom_boxplot() +
  labs(title = "Predicted Probability of Fistula by Religion",
       x = "Religion",
       y = "Predicted Probability") +
  theme_minimal()

# 绘制预测概率与职业的关系
ggplot(data1, aes(x = occupation, y = predicted_prob)) +
  geom_boxplot() +
  labs(title = "Predicted Probability of Fistula by Occupation",
       x = "Occupation",
       y = "Predicted Probability") +
  theme_minimal()

```

```{r}
# 下采样+ggplot重要性

# 安装并加载必要的包
library(randomForest)
library(caret)
library(dplyr)
library(ggplot2)

# 新建一个数据集，去掉 country 列
data_model <- data1 %>% select(-country)

# 确保 experienced_fistula 是因子变量
data_model$experienced_fistula <- as.factor(data_model$experienced_fistula)

# 检查转换是否成功
str(data_model$experienced_fistula)

# 使用 caret 包中的 downSample 函数进行下采样
set.seed(123)  # 设置随机种子以保证结果可重复
data_downsampled <-
  downSample(
    x = data_model %>% select(-experienced_fistula),
    y = data_model$experienced_fistula,
    yname = "experienced_fistula"
  )


# 标准化权重
data_downsampled$V005 <- data_downsampled$V005 / 1000000  # 确保权重处理正确


# 下采样后的目标变量从1和2改为0和1
data_downsampled$experienced_fistula <- as.numeric(data_downsampled$experienced_fistula) - 1

# 确保除V005列都是因子类型
data_downsampled <- data_downsampled %>%
  mutate(across(-V005, as.factor))

# 确保 V005 是数值变量
data_downsampled$V005 <- as.numeric(data_downsampled$V005)


# 分割数据集为训练集和测试集
set.seed(123)
train_index <- createDataPartition(data_downsampled$experienced_fistula, p = 0.8, list = FALSE)
train_data <- data_downsampled[train_index, ]
test_data <- data_downsampled[-train_index, ]

# 设置训练控制，包含权重 交叉验证
train_control <- trainControl(method = "cv", number = 10)

set.seed(123)

# 设置参数调优范围
tune_grid <- expand.grid(mtry = c(1, 3, 5, 7))

rf_model <- train(
  experienced_fistula ~ . - V005,
  data = train_data,
  method = "rf",
  trControl = train_control,
  weights = train_data$V005,
  tuneGrid = tune_grid,
  metric = "Accuracy",
  ntree = 100
)

# 查看随机森林模型结果
print(summary(rf_model))

# 生成随机森林模型预测
rf_predictions <- predict(rf_model, newdata = test_data)
rf_predictions <- factor(rf_predictions, levels = levels(test_data$experienced_fistula))

# 计算随机森林模型混淆矩阵
rf_confusion_matrix <- confusionMatrix(rf_predictions, test_data$experienced_fistula)
print(rf_confusion_matrix)

# 提取特征重要性
importance_scores <- varImp(rf_model, scale = FALSE)
print(importance_scores)

# 转换特征重要性为数据框
importance_df <- as.data.frame(importance_scores$importance)
importance_df$Variable <- rownames(importance_df)
rownames(importance_df) <- NULL

# 使用 ggplot2 可视化变量重要性
ggplot(importance_df, aes(x = reorder(Variable, Overall), y = Overall)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  xlab("Variables") +
  ylab("Importance Score") +
  ggtitle("Variable Importance in Random Forest Model") +
  theme_minimal()

# 保存变量重要性数据框
save(importance_df, file = "importance_df.RData")

# 保存训练好的模型
save(rf_model, file = "rf_model.RData")
```

```{r}
library(caret)
library(dplyr)
library(randomForest)

# 新建一个数据集，去掉 country 和 number_birth 列
data_model <- data1 %>% select(-country,-age,-age_sex,-residence)

# 确保 experienced_fistula 是因子变量
data_model$experienced_fistula <- as.factor(data_model$experienced_fistula)

# 上采样
data_upsampled <- upSample(
  x = data_model %>% select(-experienced_fistula),
  y = data_model$experienced_fistula,
  yname = "experienced_fistula"
)

# 下采样
set.seed(123)
data_downsampled <- downSample(
  x = data_upsampled %>% select(-experienced_fistula),
  y = data_upsampled$experienced_fistula,
  yname = "experienced_fistula"
)

# 合并下采样和上采样的数据集
data_combined <- rbind(data_upsampled,data_downsampled)

# 标准化权重
data_combined$V005 <- data_combined$V005 / 1000000

# 目标变量从1和2改为0和1
data_combined$experienced_fistula <- as.numeric(data_combined$experienced_fistula) - 1

# 确保所有列都是因子类型，除了 V005
data_combined <- data_combined %>%
  mutate(across(-V005, as.factor))

# 确保 V005 是数值变量
data_combined$V005 <- as.numeric(data_combined$V005)

# 分割数据集为训练集和测试集
set.seed(123)
train_index <- createDataPartition(data_combined$experienced_fistula, p = 0.7, list = FALSE)
train_data <- data_combined[train_index, ]
test_data <- data_combined[-train_index, ]


# 设置训练控制，包含权重 交叉验证
train_control <- trainControl(method = "cv", number = 10)

# 设置参数调优范围
tune_grid <- expand.grid(mtry = c(1,3, 5, 7))

# 训练随机森林模型
set.seed(123)
rf_model <- train(
  experienced_fistula ~ . - V005,
  data = train_data,
  method = "rf",
  trControl = train_control,
  weights = train_data$V005,
  tuneGrid = tune_grid,
  metric = "Accuracy",
  ntree = 200
)

# 查看随机森林模型结果
print(summary(rf_model))


# 生成随机森林模型预测
rf_predictions <- predict(rf_model, newdata = test_data)
rf_predictions <- factor(rf_predictions, levels = levels(test_data$experienced_fistula))

# 计算随机森林模型混淆矩阵
rf_confusion_matrix <- confusionMatrix(rf_predictions, test_data$experienced_fistula)
print(rf_confusion_matrix)

# 提取特征重要性
importance_scores <- varImp(rf_model, scale = FALSE)
print(importance_scores)
```

```{r}
#循环的 西非+国家

library(caret)
library(dplyr)
library(randomForest)

# 定义平衡数据的函数
balance_data <- function(data) {
  # 下采样
  set.seed(123)
  data_downsampled <- downSample(
    x = data %>% select(-experienced_fistula),
    y = data$experienced_fistula,
    yname = "experienced_fistula"
  )
  
  # 上采样
  set.seed(123)
  data_upsampled <- upSample(
    x = data %>% select(-experienced_fistula),
    y = data$experienced_fistula,
    yname = "experienced_fistula"
  )
  
  # 合并上采样和下采样数据集
  data_combined <- bind_rows(data_upsampled, data_downsampled)
  
  # 标准化权重
  data_combined$V005 <- data_combined$V005 / 1000000
  
  # 将目标变量从1和2改为0和1
  data_combined$experienced_fistula <- as.numeric(data_combined$experienced_fistula) - 1
  
  # 确保除V005列都是因子类型
  data_combined <- data_combined %>%
    mutate(across(-V005, as.factor))
  
  # 确保 V005 是数值变量
  data_combined$V005 <- as.numeric(data_combined$V005)
  
  return(data_combined)
}

# 准备西非整体数据
data_model <- data1 %>% select(-country)
data_model$experienced_fistula <- as.factor(data_model$experienced_fistula)
balanced_data_model <- balance_data(data_model)

# 定义训练和评估函数
train_and_evaluate <- function(data) {
  set.seed(123)
  train_index <- createDataPartition(data$experienced_fistula, p = 0.8, list = FALSE)
  train_data <- data[train_index, ]
  test_data <- data[-train_index, ]
  
  train_control <- trainControl(method = "cv", number = 10)
  tune_grid <- expand.grid(mtry = c(3, 5, 7))
  
  set.seed(123)
  rf_model <- train(
    experienced_fistula ~ . - V005,
    data = train_data,
    method = "rf",
    trControl = train_control,
    weights = train_data$V005,
    tuneGrid = tune_grid,
    metric = "Accuracy",
    ntree = 200
  )
  
  rf_predictions <- predict(rf_model, newdata = test_data)
  rf_confusion_matrix <- confusionMatrix(rf_predictions, test_data$experienced_fistula)
  
  return(list(model = rf_model, confusion_matrix = rf_confusion_matrix))
}

# 评估西非整体数据
results_model <- train_and_evaluate(balanced_data_model)
print(results_model$confusion_matrix)

```

glm预测

```{r}
# Predict
# 从 dhs_design 中提取数据
# dhs_data_all <- as.data.frame(dhs_design$variables)

# predicted_prob <- predict(glm_fistula_multi, newdata = dhs_data_all, type = "response")

# Create a new dataset
# data_with_predictions <- dhs_data_all %>%
#  mutate(predicted_prob = predicted_prob)

# Save the file containing the prevalence column
# write.csv(data_with_predictions, "predicted_fistula_all.csv", row.names = FALSE)
```

随机森林预测

```{r}
# Random Forest Model Prediction-data1
#rf_predictions <- predict(rf_model, newdata = data1)
#rf_predictions <- factor(rf_predictions, levels = levels(data1$experienced_fistula))

# Random Forest Model Confusion Matrix
#rf_confusion_matrix <- confusionMatrix(rf_predictions, data1$experienced_fistula)
#print(rf_confusion_matrix)

# Feature Importance
#importance_scores <- varImp(rf_model, scale = FALSE)
#print(importance_scores)
```

save model

```{r}
# Save the model
save(rf_model, file = "rf_model.RData")
#saveRDS(rf_model, file = "rf_model.rds")
```

```{r}
# RF Shiny 1
# Partial Dependence Plot
library(shiny)
library(pdp)  

# load the model
load("rf_model.RData")

# Convert all variables of type haven_labelled to factors or numeric values
data1 <- data1 %>%
  mutate(across(where(is.labelled), as_factor))

# All categorical variables are converted to factor type
factor_columns <- c("age","distance","age_sex", "number_birth", "religion", "residence", "wealth", "education", "occupation", "contraception_use", "delivery_place", "delivery_professional", "postpartum_care")

data1 <- data1 %>%
  mutate(across(all_of(factor_columns), as.factor))

# Define the four aspects and their variables
personal_vars <- c("age", "residence", "religion")
economic_vars <- c("wealth", "education", "occupation")
health_vars <- c("distance", "delivery_place", "delivery_professional", "postpartum_care")
planning_vars <- c("age_sex", "number_birth", "contraception_use")

# Create Shiny UI
ui <- fluidPage(
  titlePanel("Random Forest Model Analysis"),
  sidebarLayout(
    sidebarPanel(
      selectInput("aspect", "Select Aspect:", choices = c("Personal", "Economic", "Health", "Planning")),
      uiOutput("variable_ui"),  
      actionButton("update", "Update Plot")
    ),
    mainPanel(
      plotOutput("importance_plot"),
      plotOutput("pdp_plot")
    )
  )
)

# Create Shiny server
server <- function(input, output, session) {
  output$variable_ui <- renderUI({
    aspect_vars <- switch(input$aspect,
                          "Personal" = personal_vars,
                          "Economic" = economic_vars,
                          "Health" = health_vars,
                          "Planning" = planning_vars)
    selectInput("variable", "Select Variable:", choices = aspect_vars)
  })
  
  
  # Displaying Partial Dependence Plots
  output$pdp_plot <- renderPlot({
    req(input$update)  # Update button click
    isolate({
      pd <- partial(rf_model, pred.var = input$variable, plot = FALSE, rug = TRUE)
      autoplot(pd, main = paste("Partial Dependence Plot for", input$variable), rug = TRUE)
    })
  })
}

# Run Shiny
shinyApp(ui = ui, server = server)

```

```{r}
# RF Shiny 2
# Shiny Line Chart
library(shiny)

# All variables were converted to factor type.
factor_columns <- c("age","distance", "age_sex", "number_birth", "religion", "residence", "wealth", "education", "occupation", "contraception_use", "delivery_place", "delivery_professional", "postpartum_care")

data1 <- data1 %>%
  mutate(across(all_of(factor_columns), as.factor))

# Load the trained model
rf_model <- readRDS("rf_model.rds")

# Create Shiny UI
ui <- fluidPage(
  titlePanel("Fistula Prevalence Prediction"),
  sidebarLayout(
    sidebarPanel(
      selectInput("age", "Age:", choices = levels(data1$age)),
      selectInput("distance", "Distance:", choices = levels(data1$distance)),
      selectInput("age_sex", "Age sex:", choices = levels(data1$age_sex)),
      selectInput("number_birth", "Age sex:", choices = levels(data1$number_birth)),
      selectInput("religion", "Religion:", choices = levels(data1$religion)),
      selectInput("residence", "Residence:", choices = levels(data1$residence)),
      selectInput("wealth", "Wealth:", choices = levels(data1$wealth)),
      selectInput("education", "Education:", choices = levels(data1$education)),
      selectInput("occupation", "Occupation:", choices = levels(data1$occupation)),
      selectInput("contraception_use", "Contraception Use:", choices = levels(data1$contraception_use)),
      selectInput("delivery_place", "Delivery Place:", choices = levels(data1$delivery_place)),
      selectInput("delivery_professional", "Delivery Professional:", choices = levels(data1$delivery_professional)),
      selectInput("postpartum_care", "Postpartum Care:", choices = levels(data1$postpartum_care)),
      numericInput("V005", "Weight:", value = 1),
      actionButton("predict", "Predict")
    ),
    mainPanel(
      textOutput("prediction"),
      plotOutput("importancePlot"),
      plotOutput("trendPlot")
    )
  )
)

# Create Shiny server
server <- function(input, output) {
  predictions <- reactiveVal(data.frame())

  observeEvent(input$predict, {
    new_data <- data.frame(
      age = factor(input$age, levels = levels(data1$age)),
      distance = factor(input$distance, levels = levels(data1$distance)),
      age_sex = factor(input$age_sex, levels = levels(data1$age_sex)),
      number_birth = factor(input$age_sex, levels = levels(data1$number_birth)),
      religion = factor(input$religion, levels = levels(data1$religion)),
      residence = factor(input$residence, levels = levels(data1$residence)),
      wealth = factor(input$wealth, levels = levels(data1$wealth)),
      education = factor(input$education, levels = levels(data1$education)),
      occupation = factor(input$occupation, levels = levels(data1$occupation)),
      contraception_use = factor(input$contraception_use, levels = levels(data1$contraception_use)),
      delivery_place = factor(input$delivery_place, levels = levels(data1$delivery_place)),
      delivery_professional = factor(input$delivery_professional, levels = levels(data1$delivery_professional)),
      postpartum_care = factor(input$postpartum_care, levels = levels(data1$postpartum_care)),
      V005 = as.numeric(input$V005)
    )
    
    prediction <- predict(rf_model, newdata = new_data, type = "prob")
    adjusted_prevalence <- prediction[, 2]
    
    output$prediction <- renderText({
      paste("Predicted Probability of Fistula: ", round(adjusted_prevalence * 100, 2), "%")
    })
    
    # Update the trend data
    pred_data <- predictions()
    pred_data <- rbind(pred_data, data.frame(Time = nrow(pred_data) + 1, Prevalence = adjusted_prevalence))
    predictions(pred_data)
  })
  
  output$importancePlot <- renderPlot({
    importance_scores <- varImp(rf_model, scale = FALSE)
    plot(importance_scores, main = "Variable Importance")
  })
  
  output$trendPlot <- renderPlot({
    pred_data <- predictions()
    if (nrow(pred_data) > 0) {
      plot(pred_data$Time, pred_data$Prevalence, type = "o", col = "blue", ylim = c(0, 1),
           xlab = "Time", ylab = "Relative Change in Prevalence",
           main = "Predicted Fistula Prevalence Trend")
    }
  })
}

# Running the Shiny
shinyApp(ui = ui, server = server)

```
